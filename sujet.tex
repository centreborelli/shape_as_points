\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{amsmath}
\usepackage[osf,sups]{Baskervaldx} % lining figures
\usepackage[bigdelims,cmintegrals,vvarbb,baskervaldx,frenchmath]{newtxmath} % math font
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{url,hyperref}

% margins
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}
\addtolength{\hoffset}{-3.5em}
\addtolength{\textwidth}{7em}
\addtolength{\voffset}{-5em}
\addtolength{\textheight}{10em}


\begin{document}
\thispagestyle{empty}

{\bf
	Résolution de l'équation de Poisson par réseaux de neurones
}

{\bf Encadrants}:\\
Enric Meinhardt-Llopis \verb+<enric.meinhardt@ens-paris-saclay.fr>+\\
Rafael Grompone von Gioi \verb+<rafael.grompone@ens-paris-saclay.fr>+

{\bf Contexte}\\
Il y a trois techniques en calcul numérique qui sont bien différents, mais qui
sont néanmoins formellement similaires.  D'abord, la {\bf factorisation}
d'une matrice pleine comme produit d'un nombre petit de matrices creuses.
C'est le cas par exemple de la Transformation de Fourier Rapide, où une matrice
pleine de taille~$2^N\times2^N$ s'écrit comme produit de~$N$ matrices creuses.
Seconde, les {\bf méthodes multigrid} pour la résolution d'une EDP, où la même
équation est résolue successivement à différents pas de
discrétisation---échelles---ce qui permet une convergence considérablement plus
rapide vers la solution globale.  Troisième, l'{\bf architecture
U-Net}~\cite{unet} pour les réseaux de neurones à convolution, où la pyramide
multi-échelle d'une image est analysée successivement par plusieurs couches
convolutionnelles, puis les résultats de chaque couche sont intégrés sur une
image à la résolution initiale.
%Les réseaux U-Net, et plus en général les
%architectures du type~\emph{encoder-decoder}, sont une des briques de base du
%traitement d'images moderne; ils fournissent des résultats de l'état de l'art
%sur des problèmes de classification, segmentation et debruitage
%d'images~\cite{unet}.

\begin{tabular}{ccc}
	\sf\color{blue} Sparse matrix factorisation &
	\sf\color{blue} Multigrid PDE solvers&
	\sf\color{blue} U-Net ConvNets\\
	\includegraphics[width=0.32\linewidth]{f/butterflies.png} &
	%\includegraphics[width=0.3\linewidth]{f/multigrid.png} &
	\includegraphics[width=0.32\linewidth]{f/vcycle.png} &
	\includegraphics[width=0.32\linewidth]{f/cunet.png} \\
\end{tabular}

Si on vise à résoudre l'équation de Poisson~$\Delta u = f$ dans un domaine
rectangulaire, les deux premières techniques sont confondues; ceci vient du
fait que la transformée de Fourier diagonalise l'opérateur Laplacien.
%L'article ``Shape As Points: A Differentiable Poisson Solver''~\cite{sap}
Un article~\cite{sap} paru récemment
%, paru récemment et devenu célèbre dans la communauté
%de traiteurs de nuages de points,
clôt le cercle en proposant un réseau
de neurones pyramidal pour résoudre l'équation de Poisson.
Ce réseau, dit DPSR (Differentiable Poisson Surface Reconstruction), est ensuite
utilisé comme brique différentiable pour plusieurs applications en modélisation
de formes tridimensionnelles à partir de points isolés~\cite{psr}.
%Plus concrètement, les auteurs développent un réseau de neurones DPSR
%(Differentiable Poisson Surface Reconstruction) qui résout l'équation de
%Poisson pour
\\
%Plus concrètement, l'étape d'entrainement utilise la donnée~$f$ pour ajuster
%les poids des neurones, et l'inférence prend un point~$\mathrm{x}$ en entrée
%et donne la valeur~$u(\mathrm{x})$ en sortie.
\centerline{%
	\includegraphics[width=0.8\linewidth]{f/pipeline_optim.png}%
}



{\bf Objectif du stage}\\
L'objectif du stage est de bien comprendre cette
correspondance triple entre factorisations creuses, méthodes multigrid, et
réseaux de neurones pyramidaux.  Plus concrètement, on vise à maîtriser les
deux articles~\cite{psr,sap} fondamentaux %fondationnels
du sujet de façon théorique et expérimentale.
Ces travaux laissent beaucoup de questions ouvertes à explorer.
%Plus concrètement, on vise à maitriser les les
%deux articles~\cite{psr,sap} fondationnels du sujet, et à prendre un peu de
%recul pour se poser et répondre---de façon théorique et expérimentelle---aux
%questions intéressantes que les auteurs originaux ne se posent pas:
%Est-ce que le solver de Poisson est utilisable pour d'autres applications de
%cette équation en traitement d'images?  Qu'est-ce que l'on y gagne/perd en
%remplaçant la nonlinearité du réseau par l'identité? Peut-on ``apprendre'' des
%factorisations creuses de matrices par cette technique?  Peut-on factoriser
%exactement l'opérateur Laplacien sur un domaine discret quelconque?


%\setlength{\tabcolsep}{0pt}
%\begin{tabular}{ccccccccccc}
%	\includegraphics[width=0.093\linewidth]{f/marsmooth.png} &
%	\includegraphics[width=0.093\linewidth]{f/marbords.png} &
%	\includegraphics[width=0.093\linewidth]{f/marimba_v01.png} &
%	\includegraphics[width=0.093\linewidth]{f/marimba_v02.png} &
%	\includegraphics[width=0.093\linewidth]{f/marimba_v03.png} &
%	\includegraphics[width=0.093\linewidth]{f/marimba_v04.png} &
%	\includegraphics[width=0.093\linewidth]{f/marimba_v05.png} &
%	\includegraphics[width=0.093\linewidth]{f/marimba_v06.png} &
%	\includegraphics[width=0.093\linewidth]{f/marimba_v07.png} &
%	\includegraphics[width=0.093\linewidth]{f/marimba_v08.png} &
%	\includegraphics[width=0.093\linewidth]{f/marimba_v09.png} \\
%	$1\!\!1_\Omega$  & $W$ &
%	$\varphi_1$ &
%	$\varphi_2$ &
%	$\varphi_3$ &
%	$\varphi_4$ &
%	$\varphi_5$ &
%	$\varphi_6$ &
%	$\varphi_7$ &
%	$\varphi_8$ &
%	$\varphi_9$
%\end{tabular}


\vspace{-1.5em}
\renewcommand{\refname}{\normalsize Références}
%
\begin{thebibliography}{99}
\vspace{-1em}
{\scriptsize
\bibitem{psr}
	Kazhdan, M., Bolitho, M., \& Hoppe, H.
		{\it Poisson surface reconstruction.}
		Eurographics Symp. on Geometry processing (2006).
\bibitem{sap}
	Peng, S., Jiang, C., Liao, Y., Niemeyer, M., Pollefeys, M., \& Geiger, A.
		{\it Shape as points: A differentiable Poisson solver.}
		Advances in Neural Information Processing Systems, (2021).
		\hspace{2em}\url{https://pengsongyou.github.io/sap}
\bibitem{unet}
	Ronneberger, O., Fischer, P., \& Brox, T.
		{\it U-net: Convolutional networks for biomedical image segmentation.}
		MICCAI (2015).

%\bibitem{drum}
%	Kac, M..
%	{\it Can one hear the shape of a drum?}
%	The american mathematical monthly, (1966)
%
%\bibitem{inverse}
%	Chu, M., \& Golub, G.
%	{\it Inverse eigenvalue problems: theory, algorithms, and
%	applications}, OUP (2005)
%
%\bibitem{localfun}
%	Nguyen, B. \& Grebenkov, D.~S.
%	{\it Localization of Laplacian eigenfunctions in circular, spherical
%	and elliptical domains}, SIAM J.  Appl. Math. (2019)
%
%\bibitem{geofun}
%	Grebenkov, D.~S.  \& Nguyen, B.
%	{\it Geometrical structure of Laplacian eigenfunctions},
%	SIAM Rev. (2013)
%
%\bibitem{backeigen}
%	Wang,~W., Dang,~Z., Hu,~Y., Fua,~P., Salzmann,~M.
%	{\it Backpropagation-Friendly Eigendecomposition},
%	NeurIPS (2019)
%
}
\end{thebibliography}



\end{document}  


% vim:set tw=79 spell spelllang=fr ts=2 sw=2:
